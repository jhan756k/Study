{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu\n",
    "import os, cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "'''cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''while cv2.waitKey(33) < 0:\n",
    "    ret, frame = capture.read()\n",
    "    if ret:\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        result = cascade.detectMultiScale(\n",
    "            gray, scaleFactor=1.1, minNeighbors=10, minSize=(20, 20))\n",
    "            \n",
    "        for x, y, w, h in result:\n",
    "\n",
    "            print(x, y, x+w, y+h)\n",
    "            date = datetime.strftime(datetime.now(), \"%y%m%d-%H%M%S\")\n",
    "            cv2.imwrite(f\"./user1/{date}.png\", frame[y:y+h, x:x+h])\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h),\n",
    "                          color=(255, 255, 0), thickness=1)\n",
    "                          \n",
    "        cv2.imshow(\"Video Frame\", frame) # You can delete this to disable the window from opening \n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "lists = os.listdir(\"others\")\n",
    "\n",
    "for arg in lists:\n",
    "    dirs = \"others/\"+arg\n",
    "    is_cropped = False\n",
    "    frame = cv2.imread(dirs)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    result = cascade.detectMultiScale(\n",
    "        gray, scaleFactor=1.1, minNeighbors=10, minSize=(20, 20))\n",
    "        \n",
    "    for x, y, w, h in result:\n",
    "        is_cropped = True\n",
    "        cv2.imwrite(dirs, frame[y:y+h, x:x+h])\n",
    "    if not is_cropped:\n",
    "        os.remove(dirs)\n",
    "print(len(os.listdir(\"others\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAG 에서 사진 가져오기\n",
    "import shutil\n",
    "\n",
    "main = \"imgset\"\n",
    "target = \"others\"\n",
    "names = os.listdir(main)\n",
    "\n",
    "pictures = list()\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    files = os.listdir(f\"{main}/{name}\")\n",
    "    pictures += [f\"{main}/{name}/{pic}\" for pic in files if \".png\" in pic]\n",
    "\n",
    "    if \"y\" in files:\n",
    "        pictures += [f\"{main}/{name}/y/{pic}\" for pic in os.listdir(\n",
    "            f\"{main}/{name}/y\")]\n",
    "\n",
    "for num, pictures in enumerate(pictures):\n",
    "\n",
    "    shutil.move(pictures, f\"{target}/arg_{num}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "classes = [\"user1\", \"others\"]\n",
    "\n",
    "for dirs in classes:\n",
    "    os.makedirs(f\"trainset/{dirs}\", exist_ok=True)\n",
    "    os.makedirs(f\"dataset/{dirs}\", exist_ok=True)\n",
    "    data = os.listdir(dirs)\n",
    "    trainset = r.sample(data, k=400)\n",
    "    data = [i for i in data if i not in trainset]\n",
    "    dataset = r.sample(data, k=200)  # for datas = [i for i in datas if i not in trainset] --> \n",
    "\n",
    "    for train in trainset:\n",
    "        shutil.copy(f\"{dirs}/{train}\", f\"trainset/{dirs}\")\n",
    "\n",
    "    for test in dataset:\n",
    "        shutil.copy(f\"{dirs}/{test}\", f\"dataset/{dirs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test network with random images\n",
    "'''\n",
    "import random as r\n",
    "\n",
    "os.makedirs(\"trainset/user1\", exist_ok=True)\n",
    "trainset = r.sample(os.listdir(\"user1\"), k=400)\n",
    "dataset = r.sample(os.listdir(\"user1\"), k=200)\n",
    "\n",
    "for train in trainset:\n",
    "    shutil.copy(\"user1/{train}\", \"trainset/user1\")\n",
    "\n",
    "for test in dataset:\n",
    "    shutil.copy(\"user1/{test}\", \"dataset/user1\")\n",
    "\n",
    "os.makedirs(\"dataset/others\", exist_ok=True)\n",
    "trainset = r.sample(os.listdir(\"others\"), k=400)\n",
    "dataset = r.sample(os.listdir(\"others\"), k=200)\n",
    "\n",
    "\n",
    "for test in dataset:\n",
    "    shutil.copy(\"{dirs}/{train}\", \"dataset/{dirs}\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'trainset',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=12,\n",
    "    class_mode='binary'\n",
    ")\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'dataset',\n",
    "    target_size=(200, 200),\n",
    "    batch_size=12,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "model = Sequential()\n",
    "model.add(layers.Convolution2D(\n",
    "    64, (3, 3), input_shape=(200, 200, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(units=4096, activation='leaky_relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(units=1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(units=128, activation='relu'))\n",
    "model.add(layers.Dense(units=2, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(training_set, steps_per_epoch=5, epochs=5,\n",
    "                    validation_data=test_set, validation_steps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "for key, value in history.history.items():\n",
    "    plt.plot(value, label=key)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "def predicter_dir(dtr):\n",
    "    test = image.load_img(dtr, target_size=(200, 200, 3))\n",
    "    test = image.img_to_array(test)\n",
    "    test = np.expand_dims(test, axis=0)\n",
    "    result = model.predict(test)\n",
    "    indices = list(training_set.class_indices.keys())\n",
    "    return indices[np.argmax(result[0])]\n",
    "\n",
    "\n",
    "def predicter(pred):\n",
    "\n",
    "    pred = cv2.resize(pred, dsize=(200, 200), interpolation=cv2.INTER_AREA)\n",
    "    test = np.expand_dims(pred, axis=0)\n",
    "    result = model.predict(test)\n",
    "    indices = list(training_set.class_indices.keys())\n",
    "\n",
    "    return indices[np.argmax(result[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "save_model(model, \"face.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test:user1\")\n",
    "for pic in os.listdir(\"user1\")[350:]:\n",
    "    if (result:=predicter_dir(\"user1/\"+pic)) == \"others\":\n",
    "        print(result, pic, end=\", \")\n",
    "\n",
    "print(\"test:others\")\n",
    "for pic in os.listdir(\"others\")[:350]:\n",
    "    if (result:=predicter_dir(\"others/\"+pic)) == \"user1\":\n",
    "        print(result, pic, end=\", \")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "while cv2.waitKey(33) < 0:\n",
    "    ret, frame = capture.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        result = cascade.detectMultiScale(\n",
    "            gray, scaleFactor=1.1, minNeighbors=10, minSize=(20, 20))\n",
    "        for x, y, w, h in result:\n",
    "            cut = frame[y:y+h, x:x+w]\n",
    "            text = predicter(cut)\n",
    "            frame = cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame, text, (x, y), font, 1, (255, 255, 0), 2)\n",
    "        cv2.imshow(\"Video Frame\", frame)\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04ee5e672dec446cd6d2b040230647290e30e9c984d457f06583557a6fb08360"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
